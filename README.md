# ğŸ”© Deeppy

**Deeppy** is a flexible deep learning framework built on **PyTorch**, designed to simplify training workflows while supporting powerful research capabilities. It embraces a **modular approach** by **decoupling data, algorithms, and neural networks**, making it easy to swap components, experiment with new ideas, and customize pipelines end-to-end.



### âœ¨ Key Features

- ğŸ”§ **Modular by Design** â€“ Swap networks, algorithms, and data pipelines easily  
- ğŸ’¡ **Research-Oriented** â€“ Designed for flexibility and prototyping  
- ğŸ“‰ **Integrated Plotting & Logging** â€“ Visualize your training instantly  
- ğŸ” **XAI Tooling (Coming Soon)** â€“ Make black-box models more interpretable  
- âš¡ **Built with PyTorch** â€“ GPU, torch compile and AMP support and compatibility by default  

### ğŸ§° Current Models and Networks

-    <details> <summary><strong>ğŸ•¹ï¸ Reinforcement Learning</strong></summary>

        - [âš™ï¸  DQN](models/rl/dqn.py) 
            ğŸ“ [Tutorial](tutorials/RL_algorithm_tutorials.ipynb)

        - [âš™ï¸  Double DQN](models/rl/dqn.py) - ğŸ“ [Tutorial](tutorials/RL_algorithm_tutorials.ipynb)


        - [âš™ï¸  SAC](models/rl/sac.py) - ğŸ“ [Tutorial](tutorials/RL_algorithm_tutorials.ipynb)
        
</details>

- <details> <summary><strong>ğŸ“¢ Natural Language Processing<strong></summary>

    - [âš™ï¸  GPT](models/nlp/gpt.py) 
        ğŸ“ [Tutorial](tutorials/GPT-tutorial.ipynb)

</details>

- <details> <summary><strong>ğŸ–¼ï¸ Computer Vision<strong></summary>

    - [âš™ï¸  SANE](models/cv/sane.py) ğŸ“ [Tutorial](tutorials/SANE_tutorial.ipynb.ipynb)

    - [âš™ï¸  NeRF](models/cv/nerf.py) 
</details>

- <details> <summary><strong>ğŸ” Autoencoders<strong></summary>

    - [âš™ï¸  B-VAE](models/autoencoder/b_vae.py) 
    
</details>

- <details> <summary><strong>ğŸ”¬ Basic Model<strong></summary>

    - [âš™ï¸  Model](models/base_model.py) 
        
        ğŸ“ [Introduction Tutorial](tutorials/introduction.ipynb) 
    
        ğŸ“ [Advanced Tutorial](tutorials/networks_advanced.ipynb)

</details>
</div>




# âš¡ Quickstart Demos

> ğŸ’¡ Minimal examples to see Deeppy in action in under 1 minute.

<details open>
<summary>ğŸ§  <strong>Train Your Own GPT Model</strong></summary>


### ğŸ“ Step 1: Load Your Dataset

```python
with open("assets/shakespeare.txt", "r", encoding = "utf-8") as f:
    text = f.read()

encoding = tiktoken.encoding_for_model("gpt-2")
data = GPTText(text=text, tokenizer=encoding, context_size = context_size)
```

### ğŸ§± Step 2: Build the GPT-Model

```python
GPT_params = {
    "optimizer_params":Optimizer_params,
    "vocab_size":vocab_size,
    "embed_dim":embed_dim,
    "num_heads":num_heads,
    "num_layers":num_layers,
    "context_size":context_size,
    "device":device,
    "criterion":nn.CrossEntropyLoss(ignore_index = -1),
}

model = GPT(**GPT_params)
```
ğŸ“Š Total Parameters: ~28.9M

### ğŸ” Step 3: Train the Model
```python
lf = LearnFrame(model,data)

for i in range(epoch):
    lf.optimize()
lf.plot(show_result=True, log=True)
```
![](tutorials/assets/GPT.png)

### âœï¸ Step 4: Generate Text
```python
model.generate("KING RICHARD III: \n On this very beautiful day, let us")
```
KING RICHARD III: 

 On this very beautiful day, let us us hear
 
The way of the king.


DUKE OF YORK::

I will not be avoided'd with my heart.

DUKEKE VINCENTIO:

I thank you, good father.

LLUCIO:

I thank you, good my lord; I'll to your your daughter.

KING EDWARD IV:

Now, by the jealous queen

</details>

<details> <summary>ğŸ® <strong>Train a RL Agent</strong></summary>

	
### ğŸŒ Step 1: Set Up Environment

```python
import deeppy as dp

env = gym.make("LunarLander-v1")
data = dp.EnvData(env, buffer_size=100000)
```  
### ğŸ§  Step 2: Create Your Network
```python
policy_network = {
    "layers" : [obs,128,128,act],
    "blocks" : [nn.Linear, nn.ReLU]
    "out_act" : nn.Softmax,
    "weight_init" : "uniform"
}
``` 
### âš™ï¸ Step 3: Choose a RL Algorithm
```python
model = dp.SAC(**sac_params) #Soft Actor Critic
``` 
### ğŸ§ª Step 4: Train the Agent
```python
lf = dp.LearningFrame(model, data)

for epoch in range(EPOCH):
	#Take one step in environment using the model
	lf.collect()
	#Train SAC one step
	lf.optimize()
#Automatic plotting 
lf.plot()
``` 
![](tutorials/assets/plot.jpg)

### ğŸ¥ Step 5: Watch Your Agent
```python
lf.get_anim()
``` 
![](tutorials/assets/lunarlander.gif)
### ğŸ’¾ Step 6: Save / Load Your Model
```python
lf.save(file_name)
lf.load(file_name)
```

</details>


## ğŸ“š Explore More Tutorials

Looking to dive deeper? We've included hands-on examples covering everything from GPT training to reinforcement learning agents like LunarLander.

ğŸ“‚ **Find them all in the [`tutorials/`](tutorials) folder**.





# ğŸ› ï¸ Setup
```bash
pip install -r requirements.txt
```
# ğŸ“– Documentation

Documentation is in progress. Meanwhile, refer to the tutorials folder.

![](tutorials/assets/diagram.png)


# ğŸ§ª To-Do / Planned Features

### RL

<details> <summary><strong>RL</strong></summary>

Dueling DQN

PPO

MBPO (Model-Based Policy Optimization)

SafeMBPO

</details>

### XAI Tools (Explainable AI)

### Neuroevolution


