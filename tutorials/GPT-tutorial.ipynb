{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45704f5f-da5d-403d-8834-cea4bed271a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to the parent module\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import deeppy as dp\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "\n",
    "from deeppy import LearnFrame,LayerGenerator,FromLoader\n",
    "from deeppy.models.nlp.gpt import GPT\n",
    "from deeppy import GPTText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7942a0a-e548-4133-a6ec-679c32cf5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-2\")\n",
    "\n",
    "\n",
    "vocab_size = encoding.n_vocab\n",
    "context_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aef956c-d931-4d71-b77e-0968daea2cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"assets/shakespeare.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "data = GPTText(text=text, tokenizer=encoding, context_size = context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "668ff260-5d8a-49c5-bebb-e224ee0cb537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters : 3.267584 Million\n"
     ]
    }
   ],
   "source": [
    "Optimizer_params = {\n",
    "    \"optimizer\":optim.AdamW,\n",
    "    \"optimizer_args\":{\"lr\":5e-4, \"amsgrad\" : True, \"weight_decay\" : 0, \"betas\" : (0.9, 0.95)},\n",
    "    \"clipper\":nn.utils.clip_grad_norm_,\n",
    "    \"clipper_params\":{\"max_norm\" : 1.0},\n",
    "    \"scheduler_params\":None,\n",
    "}\n",
    "\n",
    "GPT_params = {\n",
    "    \"optimizer_params\":Optimizer_params,\n",
    "    \"vocab_size\":vocab_size,\n",
    "    \"embed_dim\":256,\n",
    "    \"num_heads\":5,\n",
    "    \"num_layers\":5,\n",
    "    \"context_size\":context_size,\n",
    "    \"device\":device,\n",
    "    \"criterion\":nn.CrossEntropyLoss(ignore_index = -1),\n",
    "}\n",
    "\n",
    "model = GPT(**GPT_params)\n",
    "\n",
    "print(f\"Total parameters : {sum(p.numel() for p in model.net.parameters()) / 1e6} Million\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ed13a2-76db-4942-b8f4-55a3f2fdeee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = LearnFrame(model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8baa7366-a465-474c-88b6-b77fad3eebea",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[0;32m----> 4\u001b[0m     lf\u001b[38;5;241m.\u001b[39moptimize()\n\u001b[1;32m      5\u001b[0m     lf\u001b[38;5;241m.\u001b[39mtest()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/is/git/deeppy/learn_frame.py:173\u001b[0m, in \u001b[0;36mLearnFrame.optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39moptimize(X)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\u001b[38;5;241m.\u001b[39mtrain_data\u001b[38;5;241m.\u001b[39mappend(train)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/is/git/deeppy/models/nlp/gpt.py:87\u001b[0m, in \u001b[0;36mGPT.optimize\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     84\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)),y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mback_propagate(loss)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = 5000\n",
    "\n",
    "for i in range(epoch):\n",
    "    lf.optimize()\n",
    "    lf.test()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        lf.plot(show_result=False, log=True)\n",
    "lf.plot(show_result=True, log=True, save = \"GPT.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e47dbb31-5533-4076-a52d-a1f88244739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On this very beautiful day, let us.\n",
      "\n",
      "\n",
      "ABKEES:\n",
      "And,,\n",
      "\n",
      "\n",
      "L:\n",
      "\n",
      "I:\n",
      "I\n",
      "I\n",
      "\n",
      ", the,\n",
      "I\n",
      "I,\n",
      "I\n",
      "I,\n",
      "And,\n",
      "I,\n",
      "\n",
      "IUS:\n",
      "IUS,\n",
      "I, the the,, the,,\n",
      "And the,\n",
      "\n",
      "And:\n",
      "I,:\n",
      "I,,,,,,,\n",
      "I the,\n"
     ]
    }
   ],
   "source": [
    "txt = \"On this very beautiful day, let us\"\n",
    "for i in range(10):\n",
    "    inp = torch.tensor(encoding.encode(txt)).unsqueeze(0)\n",
    "    out = model.generate(inp, 9).cpu()\n",
    "    inp = out\n",
    "    txt += encoding.decode(out.squeeze(0).tolist())\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb44b5-c5a5-4f66-a5a5-60e3200909fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
