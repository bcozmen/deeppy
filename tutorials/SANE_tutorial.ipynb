{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45704f5f-da5d-403d-8834-cea4bed271a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to the parent module\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import deeppy as dp\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tiktoken\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "from deeppy import LearnFrame,LayerGenerator,FromLoader\n",
    "from deeppy import Network\n",
    "from deeppy.models.cv import Sane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f6ba7f-4b5f-4aaf-bbf3-90cefd1b3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "input_dim = 20\n",
    "embed_dim = 64\n",
    "latent_dim = 128\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "context_size = 15\n",
    "dropout = 0.1\n",
    "bias = False\n",
    "projection_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "471c307d-c124-47b9-99ff-11c24f5998be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizer_params = {\n",
    "    \"optimizer\":optim.AdamW,\n",
    "    \"optimizer_args\":{\"lr\":3e-4, \"amsgrad\" : True},\n",
    "    \"clipper\":nn.utils.clip_grad_norm_,\n",
    "    \"clipper_params\":{\"max_norm\" : 1.0},\n",
    "    \"scheduler_params\":None,\n",
    "}\n",
    "\n",
    "Sane_params = {\n",
    "    \"optimizer_params\":Optimizer_params,\n",
    "    \"max_positions\" : [500,500,500],\n",
    "    \"input_dim\":input_dim,\n",
    "    \"latent_dim\":latent_dim,\n",
    "    \"projection_dim\" : projection_dim,\n",
    "    \"embed_dim\":embed_dim,\n",
    "    \"num_heads\":num_heads,\n",
    "    \"num_layers\":num_layers,\n",
    "    \"context_size\":context_size,\n",
    "    \"dropout\":dropout,\n",
    "    \"bias\" : bias,\n",
    "    \"device\":device,\n",
    "    \"gamma\" : 0.5,\n",
    "    \"ntx_temp\" : 0.1\n",
    "\n",
    "}\n",
    "\n",
    "model = dp.cv.Sane(**Sane_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e0c35-663b-4d24-b00d-7d28268ee1c1",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d56010bb-1512-4837-b2a0-c6e33b252195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assume that layer of a NN is already flattened and the following tensor\n",
      " is batch_size x cout x cr\n",
      "Inp shape : torch.Size([32, 15, 20])\n",
      "mask shape : torch.Size([128, 15, 15])\n",
      "positions shape : torch.Size([32, 15, 3])\n"
     ]
    }
   ],
   "source": [
    "cout = context_size\n",
    "cr = input_dim\n",
    "\n",
    "tokenized_input = torch.rand(size = (batch_size, cout, cr)).to(device)\n",
    "mask = torch.log(torch.randint(0,2,size = (batch_size*num_heads, cout, cout))).to(device)\n",
    "positions = torch.randint(0,500, size = (batch_size,cout,3)).to(device)\n",
    "\n",
    "tokenized_input2 = torch.rand(size = (batch_size, cout, cr)).to(device)\n",
    "mask2 = torch.log(torch.randint(0,2,size = (batch_size*num_heads, cout, cout))).to(device)\n",
    "positions2 = torch.randint(0,500, size = (batch_size,cout,3)).to(device)\n",
    "\n",
    "print(\"Assume that layer of a NN is already flattened and the following tensor\\n is batch_size x cout x cr\")\n",
    "\n",
    "\n",
    "print(f\"Inp shape : {tokenized_input.shape}\")\n",
    "print(f\"mask shape : {mask.shape}\")\n",
    "print(f\"positions shape : {positions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62627348-6290-4c12-aeec-bdcfdb79a2e9",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90139ec-afc7-440f-a17b-b63487e70a19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=64, bias=True)\n",
       "    (1): SanePositionalEmbedding(\n",
       "      (pe1): Embedding(500, 32)\n",
       "      (pe2): Embedding(500, 32)\n",
       "      (pe3): Embedding(500, 32)\n",
       "    )\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=False)\n",
       "          )\n",
       "          (linear1): Linear(in_features=64, out_features=256, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=64, bias=False)\n",
       "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (5): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (6): SanePositionalEmbedding(\n",
       "      (pe1): Embedding(500, 32)\n",
       "      (pe2): Embedding(500, 32)\n",
       "      (pe3): Embedding(500, 32)\n",
       "    )\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=False)\n",
       "          )\n",
       "          (linear1): Linear(in_features=64, out_features=256, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=64, bias=False)\n",
       "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): Linear(in_features=64, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22e61cc-0262-48ee-8322-b7ab386a3ce1",
   "metadata": {},
   "source": [
    "## Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbf9870c-2903-48b3-be88-a1f27dc042a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent space : torch.Size([32, 15, 128])\n"
     ]
    }
   ],
   "source": [
    "latent = model.encode((tokenized_input,positions, mask))\n",
    "print(f\"Latent space : {latent.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19bb2c34-7ae7-4bc6-b314-a7de7863fc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized input : torch.Size([32, 15, 64])\n",
      "Position encoding + dropout : torch.Size([32, 15, 64])\n",
      "After transformer encoder : torch.Size([32, 15, 64])\n",
      "Latent space : torch.Size([32, 15, 128])\n"
     ]
    }
   ],
   "source": [
    "T = model.autoencoder.model[0](tokenized_input)\n",
    "print(f\"Tokenized input : {T.shape}\")\n",
    "\n",
    "Tp = model.autoencoder.model[1](T,positions)\n",
    "Tp = model.autoencoder.model[2](Tp)\n",
    "print(f\"Position encoding + dropout : {Tp.shape}\")\n",
    "\n",
    "Tr = model.autoencoder.model[3](Tp, mask)\n",
    "print(f\"After transformer encoder : {Tr.shape}\")\n",
    "\n",
    "latent = model.autoencoder.model[4](Tp)\n",
    "print(f\"Latent space : {latent.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4e4679-9089-439d-838a-db408b6cd952",
   "metadata": {},
   "source": [
    "## Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ad68be0-1580-40bd-ba90-2120737a992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output : torch.Size([32, 15, 20])\n"
     ]
    }
   ],
   "source": [
    "z = model.decode((latent,positions,mask))\n",
    "print(f\"Output : {z.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d09b4233-d45d-484b-af35-1be5d73afd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder compression : torch.Size([32, 15, 64])\n",
      "Decoder position encoding + dropout : torch.Size([32, 15, 64])\n",
      "Decoder transformer : torch.Size([32, 15, 64])\n",
      "Output : torch.Size([32, 15, 20])\n"
     ]
    }
   ],
   "source": [
    "T = model.autoencoder.model[5](latent)\n",
    "print(f\"Decoder compression : {T.shape}\")\n",
    "\n",
    "T = model.autoencoder.model[6](T,positions)\n",
    "T = model.autoencoder.model[7](T)\n",
    "print(f\"Decoder position encoding + dropout : {T.shape}\")\n",
    "\n",
    "T = model.autoencoder.model[8](T,mask)\n",
    "print(f\"Decoder transformer : {T.shape}\")\n",
    "\n",
    "z = model.autoencoder.model[9](T)\n",
    "print(f\"Output : {z.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d2ec6b-f859-40c1-8171-5b4a1a1dbc63",
   "metadata": {},
   "source": [
    "## Autoencoder Full Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36a1e326-122c-4b14-b072-c243548f681d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output : torch.Size([32, 15, 20])\n"
     ]
    }
   ],
   "source": [
    "z,y, zp = model((tokenized_input,positions,mask))\n",
    "print(f\"Output : {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a811d5-a94c-4732-928b-c391941a11f5",
   "metadata": {},
   "source": [
    "# Projection Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae9e8a07-ca60-4bb7-8f71-047511dc2871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (model): Sequential(\n",
       "    (0): SqueezeLastDimention()\n",
       "    (1): Linear(in_features=1920, out_features=10, bias=False)\n",
       "    (2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=10, out_features=10, bias=False)\n",
       "    (5): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "    (6): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a67a25a1-b617-4485-9a06-c7abf472188f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent size : torch.Size([32, 15, 128])\n",
      "Projection head output size : torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "latent = model.encode((tokenized_input,positions,mask))\n",
    "p = model.project(latent)\n",
    "print(f\"Latent size : {latent.shape}\")\n",
    "print(f\"Projection head output size : {p.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b5a9b8-d3ca-476e-a132-fb7b33e5bc27",
   "metadata": {},
   "source": [
    "# Train a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b4ed7c9-735d-47fa-84ac-d0a69a9456c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train : 3.219444751739502\n"
     ]
    }
   ],
   "source": [
    "mask = torch.randint(0,2, size = tokenized_input.shape)\n",
    "mask2 = torch.randint(0,2, size = tokenized_input.shape)\n",
    "\n",
    "model.train()\n",
    "batch = (tokenized_input,positions,mask,tokenized_input2,positions2,mask2)\n",
    "loss = model.optimize(batch)\n",
    "print(f\"Loss train : {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85323026-cec9-4f5f-bd52-6eca95c72674",
   "metadata": {},
   "source": [
    "# Test a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ea6dab8-d706-460c-8cec-dd1661dc884c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train : 2.420185089111328\n"
     ]
    }
   ],
   "source": [
    "mask = torch.randint(0,2, size = tokenized_input.shape)\n",
    "mask2 = torch.randint(0,2, size = tokenized_input.shape)\n",
    "\n",
    "model.eval()\n",
    "batch = (tokenized_input,positions,mask,tokenized_input2,positions2,mask2)\n",
    "loss = model.test(batch)\n",
    "print(f\"Loss train : {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8e151-9d3e-447f-afa4-46c2ce7ec0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
